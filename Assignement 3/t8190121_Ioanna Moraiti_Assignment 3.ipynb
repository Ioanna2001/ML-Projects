{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Is Science Becoming Less Disruptive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Ioanna Moraiti <br />\n",
    ">AM: 8190121 <br />\n",
    ">Email: t8190121@aueb.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για να υπολογιστεί κατά πόσο ένα ερευνητικό έργο καινοτομεί στον τομέα του μπορεί να υπολογιστεί ένας δείκτης σύμφωνα με το πόσα μετεγεννέστερα έργα έχουν αναφορά στο συγκεκριμένο paper. Ο δείκτης αυτός ονομάζεται CD Index και αν μετριέται σε διάστημα πέντε ετών CD5. Πάνω σε αυτόν τον δείκτη βασίστηκε και το [άρθρο στο περιοδικό Nature](https://www.nature.com/articles/s41586-022-05543-x) για να δείξει την αλλαγή στα επίπεδα καινοτομίας ανά τα χρόνια. Υπάρχει όμως τρόπος υπολογισμού αυτού του δείκτη άμεσα; Σκοπός αυτής της εργασίας είναι η δημιουργία μοντέλων μηχανικής μάθησης για τον υπολογισμό του δείκτη CD5 ανάλογα με τα διάφορα χαρακτηριστικά ενός paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Αρχικά κάνουμε import όλες τις βιβλιοθήκες που θα χρησιμοποιήσουμε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ioann\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Παίρνουμε τα δεδομένα μας από τη βάση δεδομένων `publications_graph`. Επειδή ο πίνακας με τον δείκτη CD5 `cdindex` περιέχει πολλά παραπάνω στοιχεία από ότι οι υπόλοιποι πίνακες που συνδέονται με τον βασικό πίνακα `works` διαγράφουμε τα περιττά papers ώστε να επιταχύνουμε την διαδικασία\n",
    "* Στη συνέχεια διαβάζουμε τα στοιχεία και τα αποθηκεύουμε σε αντίστοιχα DataFrames ώστε να επιλεγούν τα τελικά features που θα χρησιμοποιήσουμε στο μοντέλο\n",
    "* Αφαιρούνται οι συγγραφείς και τα αντίστοιχα υδρίματα που εκπροσωπούν πολύ μικρό ποσοστό από papers. Συγκεκριμένα, επιλέχτηκαν συγγραφείς που έχουν δημοσιεύσει πάνω από 5 papers και τα υδρίματα που εκπροσωπούν πάνω από 5 συγγραφείς. Για αυτούς τους συγγραφείς και υδρίματα δημιουργούνται dummy στήλες\n",
    "* Στη συνέχεια υπολογίζεται ο μέσος όρος των χρονολογιών των references \n",
    "* Τέλος προστίθενται τα subjects. Κρατάμε τα subjects που χαρακτηρίζουν πάνω από 300 και λιγότερα από 2000 papers καθώς σε αυτά περιέχεται η πλειοψηφία. Τα υπόλοιπα θεωρούνται outliers και αφαιρούνται. Όπως και προηγουμένος, δημιουργούνται dummy στήλες\n",
    "\n",
    "Ενώνουμε όλα τα DataFrames στο τελικό DataFrame `works`. Σαν features στα μοντέλα μας θα χρησιμοποιηθούν οι επιλεγμένοι συγγραφείς, τα υδρίματά τους, ο μέσος όρος χρονολογίας των references, το αντικείμενο κάθε paper, το abstract, ο τίτλος και τα διάφορα στοιχεία που σχετίζονται με τη χρονολογία που εκδόθηκε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB Init\n",
      "SQLite Connection closed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Connect to DB and create a cursor\n",
    "    sqliteConnection = sqlite3.connect('publications_graph.db')\n",
    "    print('DB Init')\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = sqliteConnection.cursor()\n",
    "\n",
    "    # Execute a DELETE statement\n",
    "    cursor.execute('DELETE FROM cdindex WHERE cdindex.doi NOT IN (SELECT doi FROM works)')\n",
    "    sqliteConnection.commit()\n",
    "\n",
    "    # Write a query and save results into pandas DataFrame\n",
    "    query_works = 'SELECT * FROM works'\n",
    "    query_cdindex = 'SELECT * FROM cdindex'\n",
    "    query_author_affiliations = 'SELECT * FROM author_affiliations'\n",
    "    query_work_authors = 'SELECT * FROM work_authors'\n",
    "    query_work_references = 'SELECT * FROM work_references'\n",
    "    query_work_subjects = 'SELECT * FROM work_subjects'\n",
    "\n",
    "    # Create separate DataFrames\n",
    "    works = pd.read_sql_query(query_works, sqliteConnection)\n",
    "    cdindex = pd.read_sql_query(query_cdindex, sqliteConnection)  # Target\n",
    "    author_affiliations = pd.read_sql_query(query_author_affiliations, sqliteConnection)\n",
    "    work_authors = pd.read_sql_query(query_work_authors, sqliteConnection)\n",
    "    work_references = pd.read_sql_query(query_work_references, sqliteConnection)  # Median of year\n",
    "    work_subjects = pd.read_sql_query(query_work_subjects, sqliteConnection)  # Modeled with 0 or 1\n",
    "\n",
    "    # Merge and aggregate them in a single DataFrame\n",
    "    # Authors\n",
    "    # Only keep authors with orcid\n",
    "    work_authors.dropna(subset=['orcid'], inplace=True)\n",
    "    # Merge\n",
    "    work_authors = pd.merge(work_authors, author_affiliations, left_on='id', right_on='author_id', how='left')\n",
    "    work_authors.drop(columns=['id', 'author_id'], inplace=True)  # Drop unecessary columns\n",
    "    # Remove outlier authors\n",
    "    authors = work_authors['orcid'].value_counts()\n",
    "    work_authors = work_authors[work_authors['orcid'].isin(authors[authors > 5].index)]\n",
    "    # Remove outlier affiliations\n",
    "    aff = work_authors['name'].value_counts()\n",
    "    work_authors.loc[work_authors['name'].isin(aff[aff < 4].index), 'name'] = None\n",
    "    # Create dummies\n",
    "    work_authors.set_index('work_id')\n",
    "    work_authors = pd.get_dummies(work_authors, prefix='', columns=['orcid', 'name'])\n",
    "    work_authors = work_authors.groupby('work_id').sum().reset_index()\n",
    "    # Merge and create dummies\n",
    "    works = pd.merge(works, work_authors, left_on='id', right_on='work_id', how='left')\n",
    "    works.drop(columns=['work_id'], inplace=True)\n",
    "\n",
    "    # References year\n",
    "    work_references.drop(columns=['article_title', 'doi'], inplace=True)\n",
    "    work_references.dropna(subset=['year'], inplace=True)\n",
    "    work_references = work_references[work_references['year'].str.isnumeric()]\n",
    "    work_references = work_references.astype({'year': int})\n",
    "    work_references = work_references.groupby('work_id').agg('mean').reset_index()\n",
    "    work_references = work_references.astype({'year': int})\n",
    "    work_references.rename(columns={'year': 'ref_year'}, inplace=True)\n",
    "    works = pd.merge(works, work_references, left_on='id', right_on='work_id', how='left')\n",
    "    works.drop(columns=['work_id'], inplace=True)\n",
    "\n",
    "    # Subjects\n",
    "    work_subjects.rename(columns={'name': 'subject'}, inplace=True)\n",
    "    subjects = work_subjects['subject'].value_counts()\n",
    "    work_subjects = work_subjects[work_subjects['subject'].isin(subjects[(subjects > 300) & (subjects < 2000)].index)]\n",
    "    work_subjects = pd.get_dummies(work_subjects, prefix='subject')\n",
    "    work_subjects = work_subjects.groupby('work_id').sum().reset_index()\n",
    "    works = pd.merge(works, work_subjects, left_on='id', right_on='work_id', how='left')\n",
    "    works.drop(columns=['work_id'], inplace=True)\n",
    "\n",
    "    # Target\n",
    "    works = pd.merge(works, cdindex, on='doi')\n",
    "\n",
    "# Handle errors\n",
    "except sqlite3.Error as error:\n",
    "    print('Error occurred - ', error)\n",
    "\n",
    "# Close DB Connection irrespective of success\n",
    "# or failure\n",
    "finally:\n",
    "\n",
    "    if sqliteConnection:\n",
    "        sqliteConnection.close()\n",
    "        print('SQLite Connection closed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Εφώσον θέλουμε να υπολογίσουμε μια συνεχή αριθμητική τιμή θα φτιάξουμε ένα μοντέλο regression\n",
    "* Αφαιρούμε από το DataFrame `works` τις στήλες με κατηγορικά δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "works_nn = works.drop(columns=['id', 'title', 'doi'])\n",
    "works.drop(columns=['abstract', 'id', 'title', 'doi'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Γεμίζουμε με 0 τις NaN τιμές και χωρίζουμε το DataFrame σε training και testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "works.fillna(0, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(works.iloc[:, :-1],\n",
    "                                                    works['cdindex'],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Βλέπουμε πως οι στήλες έχουν πολύ διαφορετικές διακυμάνσεις. Θέλοντας να αποφύγουμε την κανονικοποίηση θα χρησιμοποιήσουμε ένα μοντέλο regression με decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_month</th>\n",
       "      <th>published_day</th>\n",
       "      <th>published_year</th>\n",
       "      <th>_0000-0001-5034-1135</th>\n",
       "      <th>_0000-0001-5114-6534</th>\n",
       "      <th>_0000-0001-5401-2996</th>\n",
       "      <th>_0000-0001-5576-636X</th>\n",
       "      <th>_0000-0001-5596-9853</th>\n",
       "      <th>_0000-0001-5647-6938</th>\n",
       "      <th>_0000-0001-5722-1347</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_Statistics and Probability</th>\n",
       "      <th>subject_Statistics, Probability and Uncertainty</th>\n",
       "      <th>subject_Strategy and Management</th>\n",
       "      <th>subject_Surfaces, Coatings and Films</th>\n",
       "      <th>subject_Surgery</th>\n",
       "      <th>subject_Urban Studies</th>\n",
       "      <th>subject_Virology</th>\n",
       "      <th>subject_Visual Arts and Performing Arts</th>\n",
       "      <th>subject_Water Science and Technology</th>\n",
       "      <th>cdindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "      <td>137641.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.283179</td>\n",
       "      <td>9.386774</td>\n",
       "      <td>2011.500360</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.010251</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.004330</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.132222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.029692</td>\n",
       "      <td>10.531503</td>\n",
       "      <td>12.332147</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085807</td>\n",
       "      <td>0.067501</td>\n",
       "      <td>0.086358</td>\n",
       "      <td>0.056193</td>\n",
       "      <td>0.100873</td>\n",
       "      <td>0.047633</td>\n",
       "      <td>0.065661</td>\n",
       "      <td>0.046944</td>\n",
       "      <td>0.062743</td>\n",
       "      <td>0.340194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       published_month  published_day  published_year  _0000-0001-5034-1135  \\\n",
       "count    137641.000000  137641.000000   137641.000000         137641.000000   \n",
       "mean          6.283179       9.386774     2011.500360              0.000058   \n",
       "std           4.029692      10.531503       12.332147              0.015248   \n",
       "min           0.000000       0.000000     1945.000000              0.000000   \n",
       "25%           3.000000       0.000000     2008.000000              0.000000   \n",
       "50%           6.000000       4.000000     2016.000000              0.000000   \n",
       "75%          10.000000      18.000000     2020.000000              0.000000   \n",
       "max          12.000000      31.000000     2021.000000              4.000000   \n",
       "\n",
       "       _0000-0001-5114-6534  _0000-0001-5401-2996  _0000-0001-5576-636X  \\\n",
       "count         137641.000000         137641.000000         137641.000000   \n",
       "mean               0.000073              0.000036              0.000036   \n",
       "std                0.019059              0.013477              0.006027   \n",
       "min                0.000000              0.000000              0.000000   \n",
       "25%                0.000000              0.000000              0.000000   \n",
       "50%                0.000000              0.000000              0.000000   \n",
       "75%                0.000000              0.000000              0.000000   \n",
       "max                5.000000              5.000000              1.000000   \n",
       "\n",
       "       _0000-0001-5596-9853  _0000-0001-5647-6938  _0000-0001-5722-1347  ...  \\\n",
       "count         137641.000000         137641.000000         137641.000000  ...   \n",
       "mean               0.000073              0.000065              0.000073  ...   \n",
       "std                0.019059              0.017259              0.019059  ...   \n",
       "min                0.000000              0.000000              0.000000  ...   \n",
       "25%                0.000000              0.000000              0.000000  ...   \n",
       "50%                0.000000              0.000000              0.000000  ...   \n",
       "75%                0.000000              0.000000              0.000000  ...   \n",
       "max                5.000000              5.000000              5.000000  ...   \n",
       "\n",
       "       subject_Statistics and Probability  \\\n",
       "count                       137641.000000   \n",
       "mean                             0.007418   \n",
       "std                              0.085807   \n",
       "min                              0.000000   \n",
       "25%                              0.000000   \n",
       "50%                              0.000000   \n",
       "75%                              0.000000   \n",
       "max                              1.000000   \n",
       "\n",
       "       subject_Statistics, Probability and Uncertainty  \\\n",
       "count                                    137641.000000   \n",
       "mean                                          0.004563   \n",
       "std                                           0.067501   \n",
       "min                                           0.000000   \n",
       "25%                                           0.000000   \n",
       "50%                                           0.000000   \n",
       "75%                                           0.000000   \n",
       "max                                           2.000000   \n",
       "\n",
       "       subject_Strategy and Management  subject_Surfaces, Coatings and Films  \\\n",
       "count                    137641.000000                         137641.000000   \n",
       "mean                          0.007396                              0.003168   \n",
       "std                           0.086358                              0.056193   \n",
       "min                           0.000000                              0.000000   \n",
       "25%                           0.000000                              0.000000   \n",
       "50%                           0.000000                              0.000000   \n",
       "75%                           0.000000                              0.000000   \n",
       "max                           2.000000                              1.000000   \n",
       "\n",
       "       subject_Surgery  subject_Urban Studies  subject_Virology  \\\n",
       "count    137641.000000          137641.000000     137641.000000   \n",
       "mean          0.010251               0.002260          0.004330   \n",
       "std           0.100873               0.047633          0.065661   \n",
       "min           0.000000               0.000000          0.000000   \n",
       "25%           0.000000               0.000000          0.000000   \n",
       "50%           0.000000               0.000000          0.000000   \n",
       "75%           0.000000               0.000000          0.000000   \n",
       "max           2.000000               2.000000          1.000000   \n",
       "\n",
       "       subject_Visual Arts and Performing Arts  \\\n",
       "count                            137641.000000   \n",
       "mean                                  0.002209   \n",
       "std                                   0.046944   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                   0.000000   \n",
       "75%                                   0.000000   \n",
       "max                                   1.000000   \n",
       "\n",
       "       subject_Water Science and Technology        cdindex  \n",
       "count                         137641.000000  137641.000000  \n",
       "mean                               0.003952       0.132222  \n",
       "std                                0.062743       0.340194  \n",
       "min                                0.000000      -1.000000  \n",
       "25%                                0.000000       0.000000  \n",
       "50%                                0.000000       0.000000  \n",
       "75%                                0.000000       0.000000  \n",
       "max                                1.000000       1.000000  \n",
       "\n",
       "[8 rows x 436 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Επιλέγουμε το `DecesionTreeRegressor` της βιβλιοθήκης `sklearn` και το κάνουμε fit σύμφωνα με το training DataFrame\n",
    "* Στο σημείο αυτό πρέπει να εξετάσουμε ποιο είναι το ιδανικό max_depth ώστε να υπολογίζεται η τιμή με επιτυχία, όμως να αποφεύγεται το φαινόμενο του overfit και το μοντέλο να μην επηρεάζεται από τον θόρυβο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works_tree = DecisionTreeRegressor(max_depth=13)\n",
    "works_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Θα κάνουμε Cross Validation με `GridSearch` για να βρούμε το ιδανικό `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=11)\n",
      "{'max_depth': 11}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = [\n",
    "  {'max_depth': list(range(1, 21))},\n",
    " ]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "clf = GridSearchCV(DecisionTreeRegressor(), parameters, cv=cv)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(cv_results['param_max_depth'], cv_results['mean_test_score'], label='True y')\n",
    "plt.xlabel('max depth')\n",
    "_ = plt.ylabel('mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Βλέπουμε ότι σωστά έχει επιλεχτεί το νούμερο 13\n",
    "* Σε εναλλακτική προσέγγιση θα μπορούσαμε να είχαμε εκτελέσει ένα feature selection για να αφαιρέσουμε τις περιττές στήλες\n",
    "* Κάνουμε την πρόβλεψη και βλέπουμε το Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE=0.16886544093960645\n"
     ]
    }
   ],
   "source": [
    "predicted = works_tree.predict(X_test)\n",
    "print(f'MAE={metrics.mean_absolute_error(y_test, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Άρα το μοντέλο που φτιάξαμε υπολογίζει τον δείκτη CD5 με μέση απόκλιση 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Η δεύτερη προσέγγιση που θα δοκιμάσουμε θα είναι με Νευρωνικό Δίκτυο, χρησιμοποιώντας τη βιβλιοθήκη `TensorFlow`\n",
    "* Αρχικά θα επεξεργαστούμε το abstract των papers\n",
    "    * Θα κάνουμε όλους τους χαρακτήρες lowercase\n",
    "    * Θα αφαιρέσουμε περιτά σύμβολα και\n",
    "    * Θα εφαρμόσουμε ένα `TextVectorization` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, r'^(<).*(>)$', '')\n",
    "    \n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                    '[%s]' % re.escape(string.punctuation),\n",
    "                                    '')\n",
    "max_features = 20000\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"multi_hot\"\n",
    ")\n",
    "vectorize_layer.adapt(works_nn['abstract'])\n",
    "works_nn['abstract'] = works_nn['abstract'].apply(\n",
    "    lambda x: (vectorize_layer(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Στη συνέχεια, επειδή χρησιμοποιούμε Νευρωνικά Δίκτυα, θα κανονικοποιήσουμε τα δεδομένα μας με έναν `MinMax` scaler\n",
    "* Τα vectors που δημιουργήσαμε στο προηγούμενο βήμα δεν έχει νόημα να κανονικοποιηθούν, επομένως προστίθενται στο τέλος"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "works = pd.DataFrame(scaler.fit_transform(works), columns=works.columns)\n",
    "works['abstract'] = works_nn['abstract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Χωρίζουμε το DataFrame σε training και testing όπως προηγουμένως"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(works.iloc[:, :-1],\n",
    "                                                    works['cdindex'],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Χτίζουμε το μοντέλο που θα εκπαιδευτεί\n",
    "* Το μοντέλο αποτελέιται από τρία dense στρώματα που έχουν σαν output την τελική τιμή υπολογισμού του CD5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compile_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(40, activation='relu'),\n",
    "        layers.Dense(40, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_compile_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Τρέχουμε το μοντέλο και βλέπουμε το Mean Absolute Error\n",
    "* Για να αποφύγουμε περιτές επαναλλήψεις και το φαινόμενο του overfit χρησιμοποιούμε τη μέθοδο EarlyStopping η οποία θα σταματήσει μετά από 10 επαναλλήψεις με ίδιο ή μεγαλύτερο validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ioann\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2581/2581 [==============================] - 18s 6ms/step - loss: 0.0145 - val_loss: 0.0077\n",
      "Epoch 2/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 3/100\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 4/100\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 5/100\n",
      "2581/2581 [==============================] - 13s 5ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 6/100\n",
      "2581/2581 [==============================] - 12s 5ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 7/100\n",
      "2581/2581 [==============================] - 14s 6ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 8/100\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 9/100\n",
      "2581/2581 [==============================] - 11s 4ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 10/100\n",
      "2581/2581 [==============================] - 13s 5ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 11/100\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 12/100\n",
      "2581/2581 [==============================] - 13s 5ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 13/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 14/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 15/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 18/100\n",
      "2581/2581 [==============================] - 14s 5ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 19/100\n",
      "2581/2581 [==============================] - 15s 6ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 20/100\n",
      " 217/2581 [=>............................] - ETA: 12s - loss: 0.0021"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stop])\n",
    "print(f'MAE={model.evaluate(X_test, y_test, verbose=1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
